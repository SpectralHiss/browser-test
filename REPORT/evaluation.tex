\chapter{Evaluation}


For the test managment interface our initial measure of success was that it works properly tested on all the browsers we set to support
ie8+ with a further confirmation of the correctness of those tests through the new tests we added namely the browser strict mode implementation.
The end-result performs that task well, and allows quite a range of tests to be added. But as we highlighted in the design and implementation section
while it enables reusing of template functions and their corresponding go server functions it doesn't provide any way of managing HTML templates
and indeed could not either check or modify those go server function, it is a direction we prefered not to go to because it entails a lot of coding
and serious security considerations. A lot of the groundwork is in place for extension, making browseraudit one step closer from .


As for the second part (building the data aggregator) we thought this was to be a fairly mundane programming task which has well defined behaviour
but ended up being quite tricky due to the rigidness of the data model for executions as well as strange behaviour  \
Nevertheless due to the RESTful way our server code is setup we ended up reusing a lot of the data model processing and simplifying the task
for other sides and as explained in the implementation section it demanded coding of interfaces that ended up being reused quite often.

Browseraudit has no equivalent , but in terms of the results we get that are presented in statistics page the closest analogue we can find is
browserscope's security tests \cite{browsercope} since they are community driver but they have only certain key tests since they are general to all
browser features. They also only test wether a browser has a particular useful security feature and not how well those features are implemented.
Our approach eliminates all doubts except maybe the intent and skill of the test writer and errors can be spotted over executions: trust then verify.

The project excels compared to caniuse.com for example who also just relies on developers authoritative input on wether browser X supports security
feature Y and correctly.



As for the other stated objective to empirically determine the effectiveness of different policy configurations on browsers to the latest security threats.\
Browseraudit succeeds in that the browser security widget will be the way to quantitatively assess how much depth and breadth we managed \
to achieve in our underlying knowlege of the security considerations . Result can range from not finding many effective attacks to the latest browsers with latest browsers\
in which case we will still need to document what policies are effective for which cases, attempt to infer general patterns for use by other developers who might not afford the \
time and effort to do so.\ .